<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Magic Gift V8.0 (Aliyun)</title>
    
    <style>
        @font-face { font-family: 'TechMono'; src: local('Courier New'), monospace; }
        body { margin: 0; background: #000; overflow: hidden; font-family: 'TechMono'; color: #00ffea; }
        #hologram-canvas { position: absolute; inset: 0; z-index: 1; }
        
        /* Âº∫Âà∂ËßÜÈ¢ëËß£Á†Å hack (iOS ÂøÖÈ°ª) */
        #webcam { position: fixed; top: -2000px; left: -2000px; width: 320px; height: 240px; opacity: 0.01; pointer-events: none; }

        /* --- ÈòøÈáå‰∫ëÈ£éÊ†ºÂä†ËΩΩÁïåÈù¢ --- */
        #loading-screen {
            position: fixed; inset: 0; background: #000; z-index: 9999;
            display: flex; flex-direction: column; justify-content: center; align-items: center;
            transition: opacity 0.5s;
        }
        .ali-logo { font-size: 24px; font-weight: bold; margin-bottom: 20px; text-shadow: 0 0 15px #00ffea; }
        
        /* ÁúüÂÆûËøõÂ∫¶Êù° */
        .progress-container { width: 60%; max-width: 300px; height: 4px; background: #333; border-radius: 2px; overflow: hidden; position: relative; }
        .progress-bar { 
            width: 0%; height: 100%; background: #00ffea; 
            box-shadow: 0 0 10px #00ffea; transition: width 0.2s; 
        }
        .loading-text { margin-top: 15px; color: #888; font-size: 12px; letter-spacing: 1px; }

        /* UI */
        .hud-layer { position: absolute; width: 100%; pointer-events: none; padding: 15px; box-sizing: border-box; }
        .hud-top { top: 0; display: flex; justify-content: space-between; z-index: 20; }
        .back-btn { pointer-events: auto; color: #00ffea; border: 1px solid #00ffea; padding: 5px 12px; text-decoration: none; font-size: 12px; background: rgba(0,0,0,0.5); backdrop-filter: blur(4px); }
        #gesture-status { position: absolute; bottom: 80px; left: 0; width: 100%; text-align: center; font-size: 12px; color: #fff; text-shadow: 0 0 5px cyan; opacity: 0.8; z-index: 10; }
        .left-dock { position: absolute; left: 10px; top: 50%; transform: translateY(-50%); display: flex; flex-direction: column; gap: 10px; pointer-events: auto; z-index: 30; }
        .deco-btn { width: 40px; height: 40px; border-radius: 50%; border: 1px solid rgba(0,255,234,0.3); background: rgba(0,0,0,0.5); color: #00ffea; font-size: 18px; display: flex; justify-content: center; align-items: center; cursor: pointer; }
        .bottom-dock { position: absolute; bottom: 20px; width: 100%; text-align: center; pointer-events: auto; z-index: 30; }
        .upload-btn { border: 1px solid #00ffea; padding: 10px 30px; color: #00ffea; background: rgba(0,50,50,0.5); font-size: 12px; border-radius: 20px; display: inline-block;}
        #file-input { display: none; }
        #webcam-preview { position: absolute; top: 10px; right: 10px; width: 80px; height: 60px; border: 1px solid #333; opacity: 0; z-index: 5; transform: scaleX(-1); transition: opacity 0.5s; }
    </style>

    <script type="importmap">
    {
        "imports": {
            "three": "https://registry.npmmirror.com/three/0.160.0/files/build/three.module.js",
            "three/addons/": "https://registry.npmmirror.com/three/0.160.0/files/examples/jsm/",
            "@mediapipe/tasks-vision": "https://registry.npmmirror.com/@mediapipe/tasks-vision/0.10.8/files/+esm"
        }
    }
    </script>
</head>
<body>

    <div id="loading-screen">
        <div class="ali-logo">SYSTEM LOADING</div>
        <div class="progress-container">
            <div class="progress-bar" id="p-bar"></div>
        </div>
        <div class="loading-text" id="loading-msg">Connecting to Aliyun Node...</div>
    </div>

    <div class="hud-layer hud-top">
        <div style="font-size:12px;">‚óè LIVE (CN)</div>
        <a href="mission.html" class="back-btn">EXIT</a>
    </div>

    <canvas id="hologram-canvas"></canvas>
    <div class="left-dock">
        <div class="deco-btn" onclick="addDeco('STAR')">‚òÖ</div>
        <div class="deco-btn" onclick="addDeco('GIFT')">üéÅ</div>
        <div class="deco-btn" onclick="addDeco('SOCK')">üß¶</div>
    </div>
    <div id="gesture-status">INITIALIZING...</div>
    <canvas id="webcam-preview"></canvas>
    <video id="webcam" autoplay playsinline muted></video>
    <div class="bottom-dock">
        <label class="upload-btn">üì∑ UPLOAD PHOTO<input type="file" id="file-input" multiple accept="image/*"></label>
    </div>

    <script type="module">
        import * as THREE from 'three';
        import { EffectComposer } from 'three/addons/postprocessing/EffectComposer.js';
        import { RenderPass } from 'three/addons/postprocessing/RenderPass.js';
        import { UnrealBloomPass } from 'three/addons/postprocessing/UnrealBloomPass.js';
        import { FilesetResolver, HandLandmarker } from '@mediapipe/tasks-vision';

        // Áä∂ÊÄÅ
        let handLandmarker = undefined;
        let video = document.getElementById('webcam');
        let aiReady = false;
        const pBar = document.getElementById('p-bar');
        const lMsg = document.getElementById('loading-msg');

        // --- 1. ÂêØÂä®ÊµÅÁ®ã ---
        async function launch() {
            try {
                initThree(); // 3D ËÉåÊôØÁßíÂºÄ
                
                // Âπ∂Ë°å‰ªªÂä°
                lMsg.innerText = "Requesting Camera...";
                updateProgress(10);
                const cameraTask = startCamera();
                
                lMsg.innerText = "Downloading AI Model (7.5MB)...";
                // ÂºÄÂßã‰∏ãËΩΩ AIÔºåÂπ∂ÁõëÂê¨ËøõÂ∫¶ÔºàÊ®°ÊãüÔºâ
                const aiTask = loadAI();
                
                // Âè™Ë¶ÅÊëÑÂÉèÂ§¥Â•Ω‰∫ÜÔºåÂÖàÊîæË°å
                await cameraTask;
                updateProgress(40);
                
                // Á≠âÂæÖ AI Âä†ËΩΩ
                await aiTask;
                updateProgress(100);
                lMsg.innerText = "SYSTEM READY";
                
                setTimeout(() => {
                    const loader = document.getElementById('loading-screen');
                    loader.style.opacity = 0;
                    setTimeout(()=>loader.remove(), 500);
                    startLoop();
                }, 500);

            } catch (e) {
                console.error(e);
                lMsg.innerText = "Error: " + e.message;
                lMsg.style.color = "red";
            }
        }

        function updateProgress(val) {
            pBar.style.width = val + '%';
        }

        // --- 2. ÊëÑÂÉèÂ§¥ ---
        async function startCamera() {
            if (!navigator.mediaDevices?.getUserMedia) return false;
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: "user", width: {ideal: 320}, height: {ideal: 240} }
                });
                video.srcObject = stream;
                return new Promise(r => {
                    video.onloadedmetadata = () => { video.play(); r(true); };
                });
            } catch(e) {
                console.warn("Camera denied");
                return false;
            }
        }

        // --- 3. AI Âä†ËΩΩ (Ê∑∑ÂêàÂä†ÈÄü) ---
        async function loadAI() {
            // ÂºïÊìéÔºö‰ªéÈòøÈáå‰∫ë npmmirror Âä†ËΩΩ (WASMÊñá‰ª∂Á∫¶4MBÔºåÈ£ûÂø´)
            const vision = await FilesetResolver.forVisionTasks(
                "https://registry.npmmirror.com/@mediapipe/tasks-vision/0.10.8/files/wasm"
            );
            
            // Ê®°ÊãüÂ§ßÊñá‰ª∂‰∏ãËΩΩËøõÂ∫¶ (ÊèêÂçá‰ΩìÈ™å)
            let fakeP = 40;
            const timer = setInterval(() => {
                if(fakeP < 90) { fakeP++; updateProgress(fakeP); }
            }, 100);

            // Ê®°ÂûãÔºö‰ªéÊÇ®Ëá™Â∑±ÁöÑÊúçÂä°Âô®Âä†ËΩΩ (./wasm/hand_landmarker.task)
            // 7.5MBÔºåËµ∞ÊÇ®Ëá™Â∑±ÁöÑÊµÅÈáè
            handLandmarker = await HandLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "./wasm/hand_landmarker.task",
                    delegate: "GPU"
                },
                runningMode: "VIDEO",
                numHands: 1
            });
            
            clearInterval(timer);
            aiReady = true;
            document.getElementById('gesture-status').innerText = "HAND TRACKING ACTIVE";
        }

        // --- 4. 3D Ê∏≤Êüì (‰øùÁïôÂÆåÊï¥Á≤íÂ≠êÊïàÊûú) ---
        let scene, camera, renderer, composer, group;
        const particles = [];
        
        function initThree() {
            scene = new THREE.Scene(); 
            camera = new THREE.PerspectiveCamera(45, window.innerWidth/window.innerHeight, 0.1, 1000);
            camera.position.set(0, 6, 45);
            renderer = new THREE.WebGLRenderer({canvas: document.getElementById('hologram-canvas'), alpha:true});
            renderer.setSize(window.innerWidth, window.innerHeight);
            const rp = new RenderPass(scene, camera);
            const bp = new UnrealBloomPass(new THREE.Vector2(window.innerWidth, window.innerHeight), 1.5, 0.6, 0.85);
            composer = new EffectComposer(renderer); composer.addPass(rp); composer.addPass(bp);
            group = new THREE.Group(); scene.add(group);
            
            // ÈÄ†Ê†ë (ÂéüÊ±ÅÂéüÂë≥ÁöÑÁ≤íÂ≠êÊ†ë)
            const geo = new THREE.TetrahedronGeometry(0.5);
            const mat = new THREE.MeshBasicMaterial({color: 0x00ffea, transparent:true, opacity:0.8});
            for(let i=0; i<900; i++) {
                const mesh = new THREE.Mesh(geo, mat);
                const t = Math.random(); const y = t*30 - 15; const r = (1-t)*10; const a = Math.random()*6.28;
                mesh.position.set(Math.cos(a)*r, y, Math.sin(a)*r);
                mesh.userData = { 
                    basePos: mesh.position.clone(),
                    scatterPos: new THREE.Vector3((Math.random()-0.5)*60, (Math.random()-0.5)*60, (Math.random()-0.5)*60),
                };
                group.add(mesh); particles.push(mesh);
            }
            const light = new THREE.PointLight(0x00ffff, 1, 100); light.position.set(10, 10, 10); scene.add(light);
            scene.add(new THREE.AmbientLight(0xffffff, 0.5));
        }

        window.addDeco = (type) => {
            const colors = {STAR:0xffff00, GIFT:0xff0000, SOCK:0x00ff00, APPLE:0xff0000, BAUBLE:0x0000ff};
            const m = new THREE.Mesh(new THREE.SphereGeometry(1), new THREE.MeshBasicMaterial({color: colors[type] || 0xffffff}));
            m.position.set((Math.random()-0.5)*15, Math.random()*20-5, 8);
            group.add(m);
        }

        // Âæ™ÁéØ
        const webcamCtx = document.getElementById('webcam-preview').getContext('2d');
        document.getElementById('webcam-preview').width = 160;
        document.getElementById('webcam-preview').height = 120;

        function startLoop() {
            function render() {
                let handDetected = false;
                if (aiReady && video.readyState >= 2) {
                    let results;
                    try { results = handLandmarker.detectForVideo(video, performance.now()); } catch(e){}
                    webcamCtx.drawImage(video, 0, 0, 160, 120);
                    if(results && results.landmarks.length > 0) {
                        handDetected = true;
                        const lm = results.landmarks[0];
                        const wrist = lm[0]; const tip = lm[12]; 
                        const dist = Math.hypot(tip.x-wrist.x, tip.y-wrist.y);
                        document.getElementById('gesture-status').innerText = dist > 0.3 ? "‚úã OPEN: SCATTER" : "‚úä FIST: SPIN";
                        if (dist > 0.3) {
                            particles.forEach(p => p.position.lerp(p.userData.scatterPos, 0.08));
                        } else {
                            particles.forEach(p => p.position.lerp(p.userData.basePos, 0.1));
                            group.rotation.y += 0.1;
                        }
                    }
                }
                if (!handDetected) {
                    group.rotation.y += 0.005;
                    particles.forEach(p => p.position.lerp(p.userData.basePos, 0.05));
                }
                composer.render();
                requestAnimationFrame(render);
            }
            render();
        }
        
        document.addEventListener('click', (e) => {
            if(e.clientY < 50 && e.clientX > window.innerWidth - 50) {
                document.getElementById('webcam-preview').style.opacity = 
                    document.getElementById('webcam-preview').style.opacity == 1 ? 0 : 1;
            }
        });

        const fileInput = document.getElementById('file-input');
        fileInput.addEventListener('change', (e) => {
            if(e.target.files[0]) {
                const reader = new FileReader();
                reader.onload = (ev) => {
                    const tex = new THREE.TextureLoader().load(ev.target.result);
                    const photo = new THREE.Mesh(new THREE.PlaneGeometry(5,5*0.75), new THREE.MeshBasicMaterial({map:tex, side:THREE.DoubleSide}));
                    photo.position.z = 10;
                    group.add(photo);
                    alert("Photo Added!");
                };
                reader.readAsDataURL(e.target.files[0]);
            }
        });

        launch();
    </script>
</body>
</html>
